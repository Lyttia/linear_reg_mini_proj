---
title: "Least Squares Regression Exercise"
author: "Lyttia Cancinos-McManus"
date: "October 3, 2018"
output: html_document
---

# Exercise: least squares regression

*Use the /states.rds/ data set.* 

```{r}
states.data <- readRDS("states.rds")
```

**Fit a model predicting energy consumed per capita (energy) from the percentage of residents living in metropolitan areas (metro). Be sure to:**

**1. Examine/plot the data before fitting the model**

*summary of energy and metro columns, all rows*

```{r}
sts.en.met <- subset(states.data, select = c("metro", "energy"))
summary(sts.en.met)
```

*correlation between energy and metro*

```{r}
cor(sts.en.met, use = "pairwise")
```

**Plot the data to look for multivariate outliers, non-linear relationships etc.**

*scatter plot of energy vs metro*

```{r}
plot(sts.en.met)
```

*According to the scatterplot, there is a slight negative linear association between the percentage of residents living in metropolitan areas (metro) and energy consumption per capita.* 

**2. Print and interpret the model `summary'**

*Fit regression model*

```{r}
en.met.mod <- lm(energy ~ metro, # regression formula
              data=states.data) # data set
```

*Summarize and print the results*

```{r echo=TRUE}
summary(en.met.mod) # show regression coefficients table
```

**Interpretation:**

*independent variable (metro) coefficient: -2.2871 (indicates a slight negative relationship between the percentage of residents living in metropolitan areas (metro) and energy consumption per capita.), metro significance: 0.05 (slightly significant)* 

*Adjusted R-squared: 0.097, not very high, verifying the scatterplot we saw earlier. I wouldn't use this model with metro as the only indicator for predicting energy consuption per capita. It is not very accurate at this point, but adding more indicators could help improve the prediction accuracy.*

**3. `plot' the model to look for deviations from modeling assumptions**

```{r}
plot(en.met.mod)
```

**Select one or more additional predictors to add to your model and repeat steps 1-3. Is this model significantly better than the model with /metro/ as the only predictor?**

***I chose to add "pop" and "toxic" as additional predictors to my model."Pop" being a way to measure the consumers of energy, and "toxic", being a measure of the toxic waste product produced by energy consumption.***

```{r}
states.info <- data.frame(attributes(states.data)[c("names", "var.labels")])
View(states.info)
sts.en.met.pop.toxic <- subset(states.data, select = c("energy", "metro", "pop", "toxic"))
summary(sts.en.met.pop.toxic)
plot(sts.en.met.pop.toxic)
cor(sts.en.met.pop.toxic, use = "pairwise")
mod.en.met.pop.toxic <- lm(energy ~ metro + pop + toxic, data = states.data)
summary(mod.en.met.pop.toxic)
anova(en.met.mod, mod.en.met.pop.toxic)
```

**Interpretation:**

*Independent variables "pop" and "toxic" are positively associated with energy consumption per capita, with toxic being a stronger linear association.*

*"Toxic" seems to be the most significant variable followed by "metro", which has lost significance points since the last model. It seems that the model containing the "pop" and "toxic" variables is significantly better than the model with "metro" as the only predictor. I would replace "pop" with another variable to test.* 

*R-squared: 0.3278 is improving, but still a bit low. I would like to see if I could improve this with the data we have.*

# Exercise: interactions and factors

*Use the states data set.*

**1. Add on to the regression equation that you created in exercise 1 by generating an interaction term and testing the interaction.**

```{r}
mod.en.metro.by.toxic <- lm(energy ~ metro * toxic, data = states.data)
mod.en.metro.by.toxic
```

**2. Try adding region to the model. Are there significant differences across the four regions?**

*make sure R knows region is categorical*
```{r}
str(states.data$region)
states.data$region <- factor(states.data$region)
```

*print default contrasts*
```{r}
contrasts(states.data$region)
```

*change the reference group*
```{r}
coef(summary(lm(csat ~ C(region, base=4),
                data=states.data)))
```

*change the coding scheme*
```{r}
coef(summary(lm(csat ~ C(region, contr.helmert),
                data=states.data)))
```

*Add region to the model*
```{r}
mod.en.region <- lm(energy ~ metro * toxic + region, data = states.data)
```

*Show the results:*
```{r echo=TRUE}
coef(summary(mod.en.region)) # show regression coefficients table
anova(mod.en.region) # show ANOVA table
```

*There are significant differences across the 4 regions. Although I am unsure why, this is interesting and calls for further investigation.*
